"""
[src/core/thinker.py]
---------------------
The 'Thinker' module is the brain and decision-making engine of PowerTrader AI.

Responsibilities:
1.  **Market Monitoring**: Continuously fetches real-time price data (Klines) from KuCoin.
2.  **Pattern Matching**:
    -   Compares the current market candle against the "Neural Memories" generated by the `Trainer`.
    -   Uses `NeuralEngine` to find the closest historical match.
3.  **Signal Generation**:
    -   Predicts future Highs and Lows based on historical outcomes.
    -   Generates "LONG" or "SHORT" signals when price action deviates from predictions (Mean Reversion).
4.  **Bounds Management**:
    -   Calculates dynamic Support and Resistance levels ("Purple Area").
    -   Applies "Gap Logic" to prevent levels from clustering too closely.

Refactoring Note:
-   Replaces `pt_thinker.py`.
-   Decoupled from the legacy monolithic loop.
-   Outputs status to `hub_data/` files, which the UI (`app.py`) reads to update the display.
"""

import os
import time
import json
import traceback
from typing import Dict, List, Any, Optional, Tuple, Set

# Colorama for colorful console output
from colorama import Fore, Style, init

from kucoin.client import Market
from src.utils.file_manager import FileManager
from src.core.neural import NeuralEngine

# Initialize colorama
init(autoreset=True)

class Thinker:
    """
    The central decision-making class.
    
    The Thinker runs in an infinite loop (in `run()`), cycling through each coin
    to check for new trading opportunities. It maintains the "State" of the market
    and writes it to disk for the Trader and UI to consume.
    
    Attributes:
        market (Market): KuCoin API client.
        tf_choices (list): Timeframes to analyze.
        distance (float): The gap distance for bounds (0.5%).
        states (dict): In-memory store of every coin's analysis state.
        display_cache (dict): Cached text for console display.
        ready_coins (set): Coins that have valid signals and are ready to trade.
        current_coins (list): The active list of coins being watched.
    """

    def __init__(self):
        """Initializes the Thinker with API clients and default state."""
        self.market = Market(url='https://api.kucoin.com')
        self.tf_choices = ['1hour', '2hour', '4hour', '8hour', '12hour', '1day', '1week']
        self.distance = 0.5
        
        # State
        self.states: Dict[str, Dict[str, Any]] = {}
        self.display_cache: Dict[str, str] = {}
        self.ready_coins: Set[str] = set()
        self.current_coins: List[str] = []
        
        # Paths
        self.hub_data_dir = os.path.join(FileManager.BASE_DIR, "hub_data")
        os.makedirs(self.hub_data_dir, exist_ok=True)
        self.runner_ready_path = os.path.join(self.hub_data_dir, "runner_ready.json")
        
        # Initialize
        self._sync_coins_from_settings()

    def _load_gui_coins(self) -> List[str]:
        """
        Reads the active coin list from `gui_settings.json`.
        
        Returns:
            List[str]: A list of symbols (e.g., ['BTC', 'ETH']).
        """
        try:
            settings_path = os.path.join(FileManager.BASE_DIR, "gui_settings.json")
            if os.path.isfile(settings_path):
                data = FileManager.load_json(settings_path)
                coins = data.get("coins", [])
                if coins:
                    return [str(c).strip().upper() for c in coins if str(c).strip()]
        except Exception:
            pass
        return ['BTC', 'ETH', 'XRP', 'BNB', 'DOGE']

    def _sync_coins_from_settings(self):
        """
        Updates the internal list of coins to match the settings file.
        
        If coins are added, it initializes their state.
        If coins are removed, it cleans up memory.
        """
        new_list = self._load_gui_coins()
        if new_list == self.current_coins:
            return

        old_list = list(self.current_coins)
        added = [c for c in new_list if c not in old_list]
        removed = [c for c in old_list if c not in new_list]

        # Handle removed coins
        for sym in removed:
            self.ready_coins.discard(sym)
            self.display_cache.pop(sym, None)
            self.states.pop(sym, None)

        # Handle added coins
        for sym in added:
            FileManager.ensure_coin_folder(sym)
            self.display_cache[sym] = f"{sym}  (starting.)"
            self._init_coin_state(sym)

        self.current_coins = list(new_list)
        self._write_runner_ready(False, "syncing")

    def _init_coin_state(self, sym: str):
        """
        Sets up the initial state dictionary for a new coin.
        
        This structure mirrors the variable sets used in the legacy `pt_thinker.py`.
        """
        st = {
            'low_bound_prices': [.01] * len(self.tf_choices),
            'high_bound_prices': [99999999999999999] * len(self.tf_choices),
            'tf_times': [],
            'tf_choice_index': 0,
            'tf_update': ['yes'] * len(self.tf_choices),
            'messages': ['none'] * len(self.tf_choices),
            'last_messages': ['none'] * len(self.tf_choices),
            'margins': [0.25] * len(self.tf_choices),
            'high_tf_prices': [99999999999999999] * len(self.tf_choices),
            'low_tf_prices': [.01] * len(self.tf_choices),
            'tf_sides': ['none'] * len(self.tf_choices),
            'messaged': ['no'] * len(self.tf_choices),
            'updated': [0] * len(self.tf_choices),
            'perfects': ['active'] * len(self.tf_choices),
            'training_issues': [0] * len(self.tf_choices),
            'bounds_version': 0,
            'last_display_bounds_version': -1,
        }
        
        # Initialize tf_times (last update timestamp for each timeframe)
        tf_times_local = []
        coin = f"{sym}-USDT"
        
        for tf in self.tf_choices:
            the_time = 0.0
            try:
                # Retry loop for initial kline fetch
                for _ in range(3):
                    try:
                        klines = self.market.get_kline(coin, tf)
                        if klines and len(klines) > 1:
                            # Use index 1 (last closed candle) to match legacy logic
                            working_minute = klines[1] 
                            the_time = working_minute[0]
                            break
                    except Exception:
                        time.sleep(1)
            except Exception:
                pass
            tf_times_local.append(the_time)
            
        st['tf_times'] = tf_times_local
        self.states[sym] = st
        
        # Initialize legacy-compatible signal files
        FileManager.write_text(sym, 'alerts_version.txt', '5/3/2022/9am')
        FileManager.write_text(sym, 'futures_long_onoff.txt', 'OFF')
        FileManager.write_text(sym, 'futures_short_onoff.txt', 'OFF')

    def _write_runner_ready(self, ready: bool, stage: str):
        """Updates the 'runner_ready.json' file for external monitoring."""
        data = {
            "timestamp": time.time(),
            "ready": bool(ready),
            "stage": stage,
            "ready_coins": sorted(list(self.ready_coins)),
            "total_coins": len(self.current_coins),
        }
        FileManager.save_json(self.runner_ready_path, data)

    def _coin_is_trained(self, sym: str) -> bool:
        """
        Verifies if the coin has valid, recent training data.
        
        Returns:
            bool: True if training data exists and is less than 14 days old.
        """
        try:
            val = FileManager.read_text(sym, "trainer_last_training_time.txt")
            if not val: return False
            ts = float(val)
            return (time.time() - ts) <= (14 * 24 * 60 * 60)
        except:
            return False

    def _get_kline_data(self, sym: str, tf: str) -> Optional[Tuple[float, float, Any]]:
        """
        Fetches the latest completed candle for a coin/timeframe.
        
        Returns:
            Tuple: (open_price, close_price, timestamp)
        """
        coin = f"{sym}-USDT"
        try:
            klines = self.market.get_kline(coin, tf)
            if klines and len(klines) > 1:
                # klines[1] is the last FULLY CLOSED candle.
                # We analyze closed candles to avoid repainting.
                c = klines[1]
                return float(c[1]), float(c[2]), c[0]
        except Exception:
            pass
        return None

    def step_coin(self, sym: str):
        """
        Performs a single analysis iteration for one coin.
        
        This is the core logic loop for a coin:
        1.  **Validation**: Checks if training data is fresh.
        2.  **Data Fetch**: Gets the latest candle.
        3.  **Pattern Analysis**: Matches current candle vs. Memory.
        4.  **Prediction**: Updates projected High/Low prices.
        5.  **Bounds Logic**: (If all TFs done) Recalculates support/resistance levels.
        
        Args:
            sym (str): The coin symbol (e.g., 'ETH').
        """
        if sym not in self.states:
            self._init_coin_state(sym)
            
        st = self.states[sym]
        
        # 1. Freshness Check
        if not self._coin_is_trained(sym):
            # If untrained, disable signals to be safe
            FileManager.write_text(sym, 'futures_long_profit_margin.txt', '0.25')
            FileManager.write_text(sym, 'futures_short_profit_margin.txt', '0.25')
            FileManager.write_text(sym, 'long_dca_signal.txt', '0')
            FileManager.write_text(sym, 'short_dca_signal.txt', '0')
            self.display_cache[sym] = f"{sym}  (NOT TRAINED / OUTDATED - run trainer)"
            self.ready_coins.discard(sym)
            self._write_runner_ready(False, "training_required")
            return

        # 2. Local State Variables
        tf_index = st['tf_choice_index']
        tf_name = self.tf_choices[tf_index]
        
        # 3. Fetch Candle
        kline = self._get_kline_data(sym, tf_name)
        if not kline:
            return # Skip if API fails
            
        open_price, close_price, candle_time = kline
        
        # Calculate current candle body size (%)
        current_candle = 0.0
        if open_price != 0:
            current_candle = 100 * ((close_price - open_price) / open_price)
            
        # 4. Load Training Data
        try:
            # Read Threshold
            thresh_str = FileManager.read_text(sym, f'neural_perfect_threshold_{tf_name}.txt')
            threshold = float(thresh_str) if thresh_str else 1.0
            
            st['training_issues'][tf_index] = 0
            
            # Read Memories
            mem_str = FileManager.read_text(sym, f'memories_{tf_name}.txt')
            w_str = FileManager.read_text(sym, f'memory_weights_{tf_name}.txt')
            hw_str = FileManager.read_text(sym, f'memory_weights_high_{tf_name}.txt')
            lw_str = FileManager.read_text(sym, f'memory_weights_low_{tf_name}.txt')
            
            # Parse lists (cleaning legacy format artifacts)
            memory_list = mem_str.replace("'", "").replace(',', '').replace('"', '').replace(']', '').replace('[', '').split('~') if mem_str else []
            weight_list = w_str.replace("'", "").replace(',', '').replace('"', '').replace(']', '').replace('[', '').split(' ') if w_str else []
            high_weight_list = hw_str.replace("'", "").replace(',', '').replace('"', '').replace(']', '').replace('[', '').split(' ') if hw_str else []
            low_weight_list = lw_str.replace("'", "").replace(',', '').replace('"', '').replace(']', '').replace('[', '').split(' ') if lw_str else []
            
            # 5. Neural Engine Logic
            current_pattern_list = [current_candle]
            
            matches_result = NeuralEngine.find_matches(
                current_pattern=current_pattern_list,
                memory_list=memory_list,
                weight_list=weight_list,
                high_weight_list=high_weight_list,
                low_weight_list=low_weight_list,
                threshold=threshold
            )
            
            # 6. Process Predictions
            final_move, final_high, final_low = matches_result["prediction"]
            matches_found = len(matches_result["matches"]) > 0
            
            if matches_found:
                st['perfects'][tf_index] = 'active'
            else:
                st['perfects'][tf_index] = 'inactive'
                final_move = 0.0
                final_high = 0.0
                final_low = 0.0

            # Persist threshold for next run
            FileManager.write_text(sym, f'neural_perfect_threshold_{tf_name}.txt', str(threshold))
            
            # 7. Calculate New High/Low Prices
            # Based on the prediction, where do we think the price is going?
            start_price = close_price
            
            if st['perfects'][tf_index] == 'inactive':
                st['high_tf_prices'][tf_index] = start_price
                st['low_tf_prices'][tf_index] = start_price
            else:
                st['high_tf_prices'][tf_index] = start_price + (start_price * final_high)
                st['low_tf_prices'][tf_index] = start_price + (start_price * final_low)
                
        except Exception as e:
            # On error, fail safe
            st['training_issues'][tf_index] = 1
            st['perfects'][tf_index] = 'inactive'
            st['high_tf_prices'][tf_index] = close_price
            st['low_tf_prices'][tf_index] = close_price

        # 8. Advance Index & Check for Wrap-Around
        # We cycle through timeframes (1h -> 2h -> ... -> 1w)
        st['tf_choice_index'] += 1
        
        # If we have processed all timeframes, we run the "Finalize" logic
        if st['tf_choice_index'] >= len(self.tf_choices):
            st['tf_choice_index'] = 0
            self._finalize_coin_loop(sym, close_price)

    def _finalize_coin_loop(self, sym: str, last_close_price: float):
        """
        Called when all timeframes have been processed for a coin.
        
        This method:
        1.  Generates Long/Short signals based on predictions vs current price.
        2.  Calculates the "Purple Area" bounds (Support/Resistance).
        3.  Applies "Gap Logic" to ensure bounds are spread out.
        4.  Writes the final signals to disk.
        """
        st = self.states[sym]
        
        # Get fresh current price for accurate signaling
        try:
            ticker = self.market.get_ticker(f"{sym}-USDT")
            current_price = float(ticker['price'])
        except:
            current_price = last_close_price
            
        n = len(self.tf_choices)
        
        # 1. Generate Messages/Signals per TF
        for i in range(n):
            cp = current_price
            high_bound = st['high_bound_prices'][i]
            low_bound = st['low_bound_prices'][i]
            high_pred = st['high_tf_prices'][i]
            low_pred = st['low_tf_prices'][i]
            
            msg = "INACTIVE"
            side = "none"
            
            if st['perfects'][i] == 'active':
                msg = "WITHIN"
                
                # Check Long: Price is below support, and we predict a bounce?
                if cp < low_bound and high_pred != low_pred:
                    msg = "LONG"
                    side = "long"
                # Check Short: Price is above resistance
                elif cp > high_bound and high_pred != low_pred:
                    msg = "SHORT"
                    side = "short"
            
            st['messages'][i] = f"{msg} on {self.tf_choices[i]}"
            st['tf_sides'][i] = side
            
            # Margin calculation
            if side == 'long':
                st['margins'][i] = ((low_bound - cp) / cp) * 100
            elif side == 'short':
                st['margins'][i] = ((high_bound - cp) / cp) * 100
            else:
                st['margins'][i] = 0.0

        # 2. Rebuild Bounds (The "Purple Area" / Gap Logic)
        # We collect all valid predictions to form new support/resistance levels.
        valid_lows = []
        valid_highs = []
        for i in range(n):
            if st['perfects'][i] != 'inactive':
                # Calculate new bounds based on distance (0.5%)
                l = st['low_tf_prices'][i] - (st['low_tf_prices'][i] * (self.distance / 100))
                h = st['high_tf_prices'][i] + (st['high_tf_prices'][i] * (self.distance / 100))
                valid_lows.append(l)
                valid_highs.append(h)
            else:
                valid_lows.append(0.01)
                valid_highs.append(99999999999999999.0)
                
        # Sort bounds to find clustering
        new_low_bound_prices = sorted(valid_lows, reverse=True)
        new_high_bound_prices = sorted(valid_highs)
        
        # Track original indices to restore order later
        og_low_index_list = []
        og_high_index_list = []
        
        for val in new_low_bound_prices:
            og_low_index_list.append(valid_lows.index(val))
        for val in new_high_bound_prices:
            og_high_index_list.append(valid_highs.index(val))
            
        # Apply Gap Logic: Push bounds apart if they are too close
        gap_modifier = 0.0
        og_index = 0
        
        while True:
            # Skip placeholders
            if (new_low_bound_prices[og_index] == 0.01 or 
                (og_index + 1 < len(new_low_bound_prices) and new_low_bound_prices[og_index + 1] == 0.01) or
                new_high_bound_prices[og_index] >= 99999999999999990.0 or
                (og_index + 1 < len(new_high_bound_prices) and new_high_bound_prices[og_index + 1] >= 99999999999999990.0)):
                pass
            elif og_index + 1 < len(new_low_bound_prices):
                # Calculate proximity
                try:
                    l1 = new_low_bound_prices[og_index]
                    l2 = new_low_bound_prices[og_index + 1]
                    low_perc_diff = (abs(l1 - l2) / ((l1 + l2) / 2)) * 100
                except:
                    low_perc_diff = 0.0
                    
                try:
                    h1 = new_high_bound_prices[og_index]
                    h2 = new_high_bound_prices[og_index + 1]
                    high_perc_diff = (abs(h1 - h2) / ((h1 + h2) / 2)) * 100
                except:
                    high_perc_diff = 0.0
                    
                # Enforce Gap
                if low_perc_diff < 0.25 + gap_modifier or l2 > l1:
                    new_price = l2 - (l2 * 0.0005)
                    del new_low_bound_prices[og_index + 1]
                    new_low_bound_prices.insert(og_index + 1, new_price)
                    continue 
                
                if high_perc_diff < 0.25 + gap_modifier or h2 < h1:
                    new_price = h2 + (h2 * 0.0005)
                    del new_high_bound_prices[og_index + 1]
                    new_high_bound_prices.insert(og_index + 1, new_price)
                    continue
            
            og_index += 1
            gap_modifier += 0.25
            if og_index >= len(new_low_bound_prices) - 1:
                break
                
        # Restore original order based on timeframe indices
        final_low_bounds = []
        final_high_bounds = []
        
        restore_index = 0
        while restore_index < len(new_low_bound_prices):
            try:
                pos = og_low_index_list.index(restore_index)
                final_low_bounds.append(new_low_bound_prices[pos])
            except:
                final_low_bounds.append(0.01)
                
            try:
                pos = og_high_index_list.index(restore_index)
                final_high_bounds.append(new_high_bound_prices[pos])
            except:
                final_high_bounds.append(99999999999999999.0)
                
            restore_index += 1
            
        st['low_bound_prices'] = final_low_bounds
        st['high_bound_prices'] = final_high_bounds
        
        # 3. Write Output Files
        longs = st['tf_sides'].count('long')
        shorts = st['tf_sides'].count('short')
        
        # Calculate Average Profit Margin
        active_margins = [m for m in st['margins'] if m != 0]
        avg_pm = sum(active_margins)/len(active_margins) if active_margins else 0.25
        if avg_pm < 0.25: avg_pm = 0.25
        
        FileManager.write_text(sym, 'futures_long_profit_margin.txt', str(avg_pm))
        FileManager.write_text(sym, 'futures_short_profit_margin.txt', str(avg_pm))
        FileManager.write_text(sym, 'long_dca_signal.txt', str(longs))
        FileManager.write_text(sym, 'short_dca_signal.txt', str(shorts))
        
        # 4. Update Ready Status
        has_predictions = any("LONG" in m or "SHORT" in m or "WITHIN" in m for m in st['messages'])
        if has_predictions:
            self.ready_coins.add(sym)
            
        all_ready = len(self.ready_coins) >= len(self.current_coins)
        self._write_runner_ready(all_ready, "active")
        
        # Cache for display
        self.display_cache[sym] = f"{sym}: {current_price}\nSignals: L:{longs} S:{shorts}\n" + "\n".join(st['messages'])

    def run(self):
        """
        The main execution loop.
        
        Runs infinitely:
        1.  Syncs settings.
        2.  Steps through every coin.
        3.  Sleeps to prevent CPU exhaustion.
        """
        print(f"{Fore.CYAN}Starting Thinker Loop...{Style.RESET_ALL}")
        while True:
            try:
                self._sync_coins_from_settings()
                
                for sym in self.current_coins:
                    self.step_coin(sym)
                    
                # Optional: Log heartbeat
                
                time.sleep(1) 
            except Exception as e:
                print(f"{Fore.RED}Thinker Error: {e}{Style.RESET_ALL}")
                traceback.print_exc()
                time.sleep(5)

if __name__ == "__main__":
    # Entry point
    thinker = Thinker()
    thinker.run()
